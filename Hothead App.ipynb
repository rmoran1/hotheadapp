{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"width: 20%; border: 1px solid black\" src=\"redbird.png\">\n",
    "<h2 style=\"text-align: center\">U MAD? cloh or naw?</h2>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # To consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For number computing\n",
    "\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# For plotting and visualization:\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# We import our access keys:\n",
    "from credentials import *    # This will allow us to use the keys as variables\n",
    "\n",
    "# API's setup:\n",
    "def twitter_setup():\n",
    "    \"\"\"\n",
    "    Utility function to setup the Twitter's API\n",
    "    with our access keys provided.\n",
    "    \"\"\"\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analize_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    '''\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# We create an extractor object:\n",
    "extractor = twitter_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user(user):\n",
    "    \n",
    "    # We create a tweet list as follows:\n",
    "    tweets = extractor.user_timeline(screen_name=user, count=200)\n",
    "    print(\"Number of tweets extracted: {}.\\n\".format(len(tweets)))\n",
    "\n",
    "    # We print the most recent 5 tweets:\n",
    "    # print(\"5 recent tweets by @{}:\\n\".format(user))\n",
    "    # for tweet in tweets[:5]:\n",
    "    #     print(tweet.text)\n",
    "    #     print()\n",
    "\n",
    "    # We create a pandas dataframe as follows:\n",
    "    data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "    # We display the first 10 elements of the dataframe:\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "    # # DISPLAY LESS INFORMATIONAL PANDA DATAFRAME\n",
    "    # display(data.head(10))\n",
    "\n",
    "    # We add relevant data:\n",
    "    data['Length']  = np.array([len(tweet.text) for tweet in tweets])\n",
    "    # data['ID']   = np.array([tweet.id for tweet in tweets])\n",
    "    data['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "    data['Source'] = np.array([tweet.source for tweet in tweets])\n",
    "    data['Likes']  = np.array([tweet.favorite_count for tweet in tweets])\n",
    "    data['RTs']    = np.array([tweet.retweet_count for tweet in tweets])\n",
    "\n",
    "    # We display the first 10 elements of the dataframe:\n",
    "    display(data.head(10))\n",
    "\n",
    "    # We extract the mean of lenghts:\n",
    "    mean = np.mean(data['Length'])\n",
    "\n",
    "    print(\"Average length of \" + user + \"'s tweets: {} characters\".format(int(mean)))\n",
    "\n",
    "    # We extract the tweet with more FAVs and more RTs:\n",
    "\n",
    "    fav_max = np.max(data['Likes'])\n",
    "    rt_max  = np.max(data['RTs'])\n",
    "\n",
    "    fav = data[data.Likes == fav_max].index[0]\n",
    "    rt  = data[data.RTs == rt_max].index[0]\n",
    "\n",
    "    # Max FAVs:\n",
    "    print(\"The tweet with the most likes is: \\n{}\".format(data['Tweets'][fav]))\n",
    "    print(\"It has {} likes.\".format(fav_max))\n",
    "    print(\"It has {} characters.\\n\".format(data['Length'][fav]))\n",
    "\n",
    "    # Max RTs:\n",
    "    print(\"The tweet with the most retweets is: \\n{}\".format(data['Tweets'][rt]))\n",
    "    print(\"It has {} retweets.\".format(rt_max))\n",
    "    print(\"It has {} characters.\\n\".format(data['Length'][rt]))\n",
    "\n",
    "    # We create time series for data:\n",
    "\n",
    "    tlen = pd.Series(data=data['Length'].values, index=data['Date'])\n",
    "    tfav = pd.Series(data=data['Likes'].values, index=data['Date'])\n",
    "    tret = pd.Series(data=data['RTs'].values, index=data['Date'])\n",
    "\n",
    "    # # Lenghts along time:\n",
    "    # tlen.plot(figsize=(16,4), color='r');\n",
    "\n",
    "    # # Likes vs retweets visualization:\n",
    "    # tfav.plot(figsize=(16,4), label=\"Likes\", legend=True)\n",
    "    # tret.plot(figsize=(16,4), label=\"Retweets\", legend=True);\n",
    "\n",
    "    # # We obtain all possible sources:\n",
    "    # sources = []\n",
    "    # for source in data['Source']:\n",
    "    #     if source not in sources:\n",
    "    #         sources.append(source)\n",
    "\n",
    "    # # We print sources list:\n",
    "    # print(\"Sources of these tweets:\")\n",
    "    # for source in sources:\n",
    "    #     print(\"* {}\".format(source))\n",
    "\n",
    "    # # We create a numpy vector mapped to labels:\n",
    "    # percent = np.zeros(len(sources))\n",
    "\n",
    "    # for source in data['Source']:\n",
    "    #     for index in range(len(sources)):\n",
    "    #         if source == sources[index]:\n",
    "    #             percent[index] += 1\n",
    "    #             pass\n",
    "\n",
    "    # percent /= 100\n",
    "\n",
    "    # # SOURCES PIE CHART\n",
    "\n",
    "    # pie_chart = pd.Series(percent, index=sources, name='Sources')\n",
    "    # pie_chart.plot.pie(fontsize=11, autopct='%.2f', figsize=(6, 6));\n",
    "\n",
    "\n",
    "\n",
    "    # We create a column with the result of the analysis:\n",
    "    data['SA'] = np.array([ analize_sentiment(tweet) for tweet in data['Tweets'] ])\n",
    "\n",
    "    # We display the updated dataframe with the new column:\n",
    "#     display(data.head(10))\n",
    "\n",
    "    # We construct lists with classified tweets:\n",
    "\n",
    "    pos_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] > 0]\n",
    "    neu_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] == 0]\n",
    "    neg_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] < 0]\n",
    "\n",
    "    # PERCENTAGE STUFF\n",
    "\n",
    "    percentPos = format(len(pos_tweets)*100/len(data['Tweets']), '.2f');\n",
    "    percentNeu = format(len(neu_tweets)*100/len(data['Tweets']), '.2f');\n",
    "    percentNeg = format(len(neg_tweets)*100/len(data['Tweets']), '.2f');\n",
    "\n",
    "    print(\"Percentage of positive tweets: {}%\".format(percentPos))\n",
    "    print(\"Percentage of neutral tweets: {}%\".format(percentNeu))\n",
    "    print(\"Percentage of negative tweets: {}%\".format(percentNeg))\n",
    "\n",
    "    # PIE CHART FOR SENTIMENT\n",
    "\n",
    "    labels = 'Positive', 'Neutral', 'Negative'\n",
    "    sentiments = [percentPos, percentNeu, percentNeg]\n",
    "    colors = ['gold', 'lightcoral', 'lightskyblue']\n",
    "    explode = (0.1, 0.1, 0.1)  # explode 1st slice\n",
    "\n",
    "    # Plot\n",
    "    plt.pie(sentiments, explode=explode, labels=labels, colors=colors,\n",
    "            autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "    maxSent = max(sentiments)\n",
    "    if ( maxSent == percentPos ):\n",
    "        print(user + \" is really positive!\")\n",
    "    elif ( maxSent == percentNeg):\n",
    "          print(user + \" is really negative.\")\n",
    "    else:\n",
    "          print(user + \" is neutral.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_location(user):\n",
    "    \n",
    "    places = extractor.geo_search(query=user, granularity=\"city\")\n",
    "    place_id = places[0].id\n",
    "\n",
    "#     print(\"TWEETS FROM THIS LOCATION\")\n",
    "    print()\n",
    "    \n",
    "    tweets = extractor.search(q=\"place:%s\" % place_id, count=200)\n",
    "    \n",
    "#     for tweet in tweets:\n",
    "#         if tweet.place:   \n",
    "#             print(tweet.text + \" | \" + tweet.place.full_name) \n",
    "#         else:\n",
    "#             print(\"Undefined place\")\n",
    "    \n",
    "    # We create a tweet list as follows:\n",
    "    print(\"Number of tweets extracted from {}: {}.\\n\".format(user, len(tweets)))\n",
    "    print()\n",
    "\n",
    "    # We print the most recent 5 tweets:\n",
    "    # print(\"5 recent tweets by @{}:\\n\".format(user))\n",
    "    # for tweet in tweets[:5]:\n",
    "    #     print(tweet.text)\n",
    "    #     print()\n",
    "\n",
    "    # We create a pandas dataframe as follows:\n",
    "    data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "    # We display the first 10 elements of the dataframe:\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "    # # DISPLAY LESS INFORMATIONAL PANDA DATAFRAME\n",
    "    # display(data.head(10))\n",
    "\n",
    "    # We add relevant data:\n",
    "    data['Length']  = np.array([len(tweet.text) for tweet in tweets])\n",
    "    data['Location'] = np.array([tweet.place.full_name for tweet in tweets])\n",
    "    # data['ID']   = np.array([tweet.id for tweet in tweets])\n",
    "    data['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "    data['Source'] = np.array([tweet.source for tweet in tweets])\n",
    "    data['Likes']  = np.array([tweet.favorite_count for tweet in tweets])\n",
    "    data['RTs']    = np.array([tweet.retweet_count for tweet in tweets])\n",
    "\n",
    "    # We display the first 10 elements of the dataframe:\n",
    "    display(data.head(10))\n",
    "\n",
    "    # We extract the mean of lenghts:\n",
    "    mean = np.mean(data['Length'])\n",
    "\n",
    "    print(\"Average length of \" + user + \"'s tweets: {} characters\".format(int(mean)))\n",
    "\n",
    "    # We extract the tweet with more FAVs and more RTs:\n",
    "\n",
    "    fav_max = np.max(data['Likes'])\n",
    "    rt_max  = np.max(data['RTs'])\n",
    "\n",
    "    fav = data[data.Likes == fav_max].index[0]\n",
    "    rt  = data[data.RTs == rt_max].index[0]\n",
    "\n",
    "    # Max FAVs:\n",
    "    print(\"The tweet with the most likes is: \\n{}\".format(data['Tweets'][fav]))\n",
    "    print(\"It has {} likes.\".format(fav_max))\n",
    "    print(\"It has {} characters.\\n\".format(data['Length'][fav]))\n",
    "\n",
    "    # Max RTs:\n",
    "    print(\"The tweet with the most retweets is: \\n{}\".format(data['Tweets'][rt]))\n",
    "    print(\"It has {} retweets.\".format(rt_max))\n",
    "    print(\"It has {} characters.\\n\".format(data['Length'][rt]))\n",
    "\n",
    "    # We create time series for data:\n",
    "\n",
    "    tlen = pd.Series(data=data['Length'].values, index=data['Date'])\n",
    "    tfav = pd.Series(data=data['Likes'].values, index=data['Date'])\n",
    "    tret = pd.Series(data=data['RTs'].values, index=data['Date'])\n",
    "\n",
    "    # # Lenghts along time:\n",
    "    # tlen.plot(figsize=(16,4), color='r');\n",
    "\n",
    "    # # Likes vs retweets visualization:\n",
    "    # tfav.plot(figsize=(16,4), label=\"Likes\", legend=True)\n",
    "    # tret.plot(figsize=(16,4), label=\"Retweets\", legend=True);\n",
    "\n",
    "    # # We obtain all possible sources:\n",
    "    # sources = []\n",
    "    # for source in data['Source']:\n",
    "    #     if source not in sources:\n",
    "    #         sources.append(source)\n",
    "\n",
    "    # # We print sources list:\n",
    "    # print(\"Sources of these tweets:\")\n",
    "    # for source in sources:\n",
    "    #     print(\"* {}\".format(source))\n",
    "\n",
    "    # # We create a numpy vector mapped to labels:\n",
    "    # percent = np.zeros(len(sources))\n",
    "\n",
    "    # for source in data['Source']:\n",
    "    #     for index in range(len(sources)):\n",
    "    #         if source == sources[index]:\n",
    "    #             percent[index] += 1\n",
    "    #             pass\n",
    "\n",
    "    # percent /= 100\n",
    "\n",
    "    # # SOURCES PIE CHART\n",
    "\n",
    "    # pie_chart = pd.Series(percent, index=sources, name='Sources')\n",
    "    # pie_chart.plot.pie(fontsize=11, autopct='%.2f', figsize=(6, 6));\n",
    "\n",
    "\n",
    "\n",
    "    # We create a column with the result of the analysis:\n",
    "    data['SA'] = np.array([ analize_sentiment(tweet) for tweet in data['Tweets'] ])\n",
    "\n",
    "    # We display the updated dataframe with the new column:\n",
    "#     display(data.head(10))\n",
    "\n",
    "    # We construct lists with classified tweets:\n",
    "\n",
    "    pos_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] > 0]\n",
    "    neu_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] == 0]\n",
    "    neg_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] < 0]\n",
    "\n",
    "    # PERCENTAGE STUFF\n",
    "\n",
    "    percentPos = format(len(pos_tweets)*100/len(data['Tweets']), '.2f');\n",
    "    percentNeu = format(len(neu_tweets)*100/len(data['Tweets']), '.2f');\n",
    "    percentNeg = format(len(neg_tweets)*100/len(data['Tweets']), '.2f');\n",
    "\n",
    "    print(\"Percentage of positive tweets: {}%\".format(percentPos))\n",
    "    print(\"Percentage of neutral tweets: {}%\".format(percentNeu))\n",
    "    print(\"Percentage of negative tweets: {}%\".format(percentNeg))\n",
    "\n",
    "    # PIE CHART FOR SENTIMENT\n",
    "\n",
    "    labels = 'Positive', 'Neutral', 'Negative'\n",
    "    sentiments = [percentPos, percentNeu, percentNeg]\n",
    "    colors = ['gold', 'lightcoral', 'lightskyblue']\n",
    "    explode = (0.1, 0.1, 0.1)  # explode 1st slice\n",
    "\n",
    "    # Plot\n",
    "    plt.pie(sentiments, explode=explode, labels=labels, colors=colors,\n",
    "            autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "    maxSent = max(sentiments)\n",
    "    if ( maxSent == percentPos ):\n",
    "        print(user + \" is really positive!\")\n",
    "    elif ( maxSent == percentNeg):\n",
    "          print(user + \" is really negative.\")\n",
    "    else:\n",
    "          print(user + \" is neutral.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = input(\"Would you like to search by username (U), or location (L)? \")\n",
    "\n",
    "print()\n",
    "if (option == \"u\"):\n",
    "    user = input(\"Please enter a location: \")\n",
    "    analyze_location(user)\n",
    "elif (option == \"l\"):\n",
    "    user = input(\"Please enter a username: @ \")\n",
    "    analyze_user(user)\n",
    "else:\n",
    "    print(\"Please enter a valid input, it's just one character!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
